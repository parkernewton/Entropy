Entropy 

Parker Newton 
5-19-15 
COEN 146L - T 2:15 pm 


Part I: Generating a Random Byte Sequence 

The source code in rand.c generates a random byte sequence and prints it to the stdout. The following explains this process: 
 * We partition the block of data to write into parts of size 256. 
 * We are sending a sequence of unsigned char's, each of length 1 byte. 
 * We maintain an array of size 256 that maps each char's ASCII value to its frequency of appearance in our data. 
 * We choose a random value between 0 and 255, and while we are in each part of size 256, we will not reuse the same char. 
 * The variable freq_count maintains the current frequency we are looking for, which corresponds to the current part of size 256 we are generating. 
 * Finally, The byte sequence is written to the stdout. 

To generate random char's: 
 * We will use rand() abs() to generate a random non-negative integer. 
 * We mod that non-negative by 256 to generate a number between 0 and 255. 
 * We map that value to a frequency stored in our frequency array.  
 * While that frequency does not equal the current frequency we are looking for (stored in the variable freq_count), we repeat the above steps. 
 * We store the randomly-generated char value into our byte sequence. 
 * We decrement the frequency of that char in freq[]. 
 * Increment the char_count. If we have reached 256 char's, then we have reached a new part, so reset the char_count to 0 and decrement the freq_count. 


Part II: Measuring Entropy 

The source code in entropy.c calculates the entropy of a byte stream by using the Shannon Entropy Formula. Entropy is calculated based on the probability of a char appearing in an element of a byte sequence.

To calculate entropy: 
 * For each possible char(0 - 255), we calculate the probability of appearance based on its frequency of appearance divided by the total number of char's we read. 
 * Entropy is dependent on the probability of appearance, and the algorithm for calculating entropy based on the Shannon Entropy Formula is described in a Cisco blog post titled "On Information Entropy" (http://blogs.cisco.com/security/on_information_entropy). 


Below are some measurements of entropy for different file sizes and types. 

Randomly-generated byte sequences: 

File Size (Bytes): 	Entropy Value: 
--------------------------------------

256 			8.0000

1024			8.0000

5120			8.0000		

20480 			8.0000

1048576			8.0000


Different Types of Files: 

File Type: 		File Size (Bytes): 		Entropy Value: 
----------------------------------------------------------------------

Text File 		46.0 				0.0000
(containing all 0's)

JPEG 			107753.0			7.9667

PNG 			236485.0			7.9587


Files of Different Sizes: 

File Type: 		File Size (Bytes): 		Entropy Value: 
----------------------------------------------------------------------

Text File 		16.0 				2.9835

PDF 			79910.0 			7.9232

PDF 			90673.0				7.9695


It is clear from the data that as file size increases, so does the entropy value. This is most probably due to the sample size of each.
Also, it appears that while a text file containing all 0's produces an entroy of 0, image files contain much higher entropy values, most probably due to how data is stored/compressed in image files. 


Part III: Compiling and Running this Project 

Two programs will need to be compiled: one to generate the random byte sequence and one to calculate entropy. 

To compile rand.c, enter on command line: 

gcc -o rand rand.c 

To compile entropy.c, enter on command line: 

gcc -o entropy entropy.c -lm 

Note the "-lm" flag appended to the command. This is a linker flag that tells the linker to link the compiled object code with the "math.h" library. 

To run the generator and entropy calculator programs, you will first have to decide how many bytes you would like to generate and test. 
Enter this value into the "#define SIZE __________" directive located at the top of the "rand.c" file. By default, this value is set to 1048576 Bytes. 

Next, you will pipe the data rand writes to the stdout into what entropy reads from the stdin using the "head" utility. On command line, run: 

./rand | head -c <file_size> | ./entropy 

Replace <file_size> with the size in bits (Multiply the value you enter into the "#define SIZE ______" directive by 8). 

To calculate the entropy of various file types, enter the following on command line: 

./entropy 	< 	<path_to_file> 

Replace <path_to_file> with the path of the file of which you wish to calculate the entropy. 

